{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9577ddf-1af7-4709-adf5-95f249b34f4b",
   "metadata": {},
   "source": [
    "# Data Exploration Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffed9472-f1bb-4ca6-b6ea-8ac31544500a",
   "metadata": {},
   "source": [
    "This notebook demonstrates Domino Data Lab's capabilities for credit card fraud detection by providing comprehensive metadata analysis of a transaction dataset. It showcases data exploration workflows including automated profiling, quality assessment, and visualization generation that data scientists would typically perform at the start of a machine learning project. The notebook serves as a reusable template for Sales Engineers to demonstrate how Domino accelerates the initial phases of model development with built-in data understanding tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d740c917-72f9-4b39-851b-28fbb882ef4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2726ef78-1738-4e53-bf71-361c2b645de8",
   "metadata": {},
   "source": [
    "## Connect to S3 Data Source Connector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1d9475-ce32-4479-94bc-6870934a4b48",
   "metadata": {},
   "source": [
    "**Domino Data Source Connectors** provide an easy and secure way to connect to external data without drivers or configuration. Direct connections use the same code you would use outside of Domino, with the flexibility to access files or data however you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeeb02f-c302-4d8f-b847-cfcadcaf695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "#### Replace With Python Snippet From Data Source ####\n",
    "######################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87da9f28-064d-4e99-8f38-d6e2cee47489",
   "metadata": {},
   "source": [
    "## Load CSV Data to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaffeae-e5b2-4bdb-aa4d-cc5e39070fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_filename = 'raw_cc_transactions.csv'\n",
    "clean_filename = 'clean_cc_transactions.csv'\n",
    "datasource_name = 'fraud-detection-workshop-bucket'\n",
    "domino_working_dir = os.environ.get(\"DOMINO_WORKING_DIR\", \".\")\n",
    "domino_project_name = os.environ.get(\"DOMINO_PROJECT_NAME\", \"my-local-project\")\n",
    "\n",
    "domino_datasource_dir = '/domino/datasets/local'\n",
    "domino_dataset_dir = f\"{domino_datasource_dir}/{domino_project_name}\"\n",
    "domino_artifact_dir = '/mnt/artifacts'\n",
    "\n",
    "object_store.download_file(\"raw_cc_transactions.csv\", f\"{domino_dataset_dir}/{raw_filename}\")\n",
    "\n",
    "raw_df = pd.read_csv(f\"{domino_dataset_dir}/{raw_filename}\")\n",
    "print(f\"Loaded {len(raw_df):,} rows from {raw_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18dd9d2-a11b-4205-bae4-ec5be3abb050",
   "metadata": {},
   "source": [
    "## Remove Dirty Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8034591e-6d4b-4f22-a148-ce6e7212ed86",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = raw_df.dropna()\n",
    "rows_removed = len(raw_df) - len(clean_df)\n",
    "pct_removed = 100 * rows_removed / len(raw_df)\n",
    "\n",
    "print(f\"üßπ Dropped {rows_removed:,} rows with missing data ({pct_removed:.2f}%)\")\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef5f7ea-f83a-4188-9da8-2afbdbc390c3",
   "metadata": {},
   "source": [
    "## Generate Dataset Metadata Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0da14c-aff1-4fbd-afb2-1dea779c2f36",
   "metadata": {},
   "source": [
    "This Python code provides detailed metadata about the credit card transactions dataset including Dataset Overview, Numerical Features Analysis, Categorical Features Analysis, Target Variable Analysis, and a Data Quality Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effc6202-d5ff-4018-bfb6-a159c0d97d73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### 1. Basic Dataset Information\n",
    "print(\"=== DATASET OVERVIEW ===\")\n",
    "print(f\"Dataset Shape: {clean_df.shape[0]:,} rows √ó {clean_df.shape[1]} columns\")\n",
    "print(f\"Memory Usage: {clean_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(f\"\\nCreated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Dataset: clean_cc_transactions.csv\")\n",
    "### 2. Column Information\n",
    "print(\"\\n=== COLUMN INFORMATION ===\")\n",
    "column_info = pd.DataFrame({\n",
    "    'Column': clean_df.columns,\n",
    "    'Data Type': clean_df.dtypes,\n",
    "    'Non-Null Count': clean_df.count(),\n",
    "    'Null Count': clean_df.isnull().sum(),\n",
    "    'Null %': (clean_df.isnull().sum() / len(clean_df) * 100).round(2),\n",
    "    'Unique Values': clean_df.nunique()\n",
    "})\n",
    "print(column_info.to_string())\n",
    "### 3. Numerical Features Summary\n",
    "print(\"\\n=== NUMERICAL FEATURES SUMMARY ===\")\n",
    "numerical_cols = clean_df.select_dtypes(include=[np.number]).columns\n",
    "print(clean_df[numerical_cols].describe().round(3))\n",
    "### 4. Categorical Features Summary\n",
    "print(\"\\n=== CATEGORICAL FEATURES SUMMARY ===\")\n",
    "categorical_cols = clean_df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    value_counts = clean_df[col].value_counts()\n",
    "    print(f\"  Unique values: {clean_df[col].nunique()}\")\n",
    "    print(f\"  Top 5 values:\")\n",
    "    for val, count in value_counts.head().items():\n",
    "        print(f\"    {val}: {count:,} ({count/len(clean_df)*100:.1f}%)\")\n",
    "### 5. Target Variable Analysis (Class Distribution)\n",
    "print(\"\\n=== TARGET VARIABLE ANALYSIS ===\")\n",
    "class_distribution = clean_df['Class'].value_counts()\n",
    "class_percentage = (class_distribution / len(clean_df) * 100).round(2)\n",
    "print(\"Class Distribution:\")\n",
    "for class_val, count in class_distribution.items():\n",
    "    print(f\"  Class {class_val}: {count:,} ({class_percentage[class_val]}%)\")\n",
    "# Calculate class imbalance ratio\n",
    "imbalance_ratio = class_distribution.max() / class_distribution.min()\n",
    "print(f\"\\nClass Imbalance Ratio: {imbalance_ratio:.2f}:1\")\n",
    "### 6. Feature Statistics\n",
    "print(\"\\n=== FEATURE STATISTICS ===\")\n",
    "# Amount statistics\n",
    "print(\"\\nTransaction Amount:\")\n",
    "print(f\"  Mean: ${clean_df['Amount'].mean():.2f}\")\n",
    "print(f\"  Median: ${clean_df['Amount'].median():.2f}\")\n",
    "print(f\"  Std Dev: ${clean_df['Amount'].std():.2f}\")\n",
    "print(f\"  Min: ${clean_df['Amount'].min():.2f}\")\n",
    "print(f\"  Max: ${clean_df['Amount'].max():.2f}\")\n",
    "# Age statistics\n",
    "print(\"\\nCustomer Age:\")\n",
    "print(f\"  Mean: {clean_df['Age'].mean():.1f} years\")\n",
    "print(f\"  Median: {clean_df['Age'].median():.1f} years\")\n",
    "print(f\"  Min: {clean_df['Age'].min():.1f} years\")\n",
    "print(f\"  Max: {clean_df['Age'].max():.1f} years\")\n",
    "# Time statistics\n",
    "print(\"\\nTransaction Time (Hour):\")\n",
    "hour_dist = clean_df['Hour'].value_counts().sort_index()\n",
    "print(f\"  Peak Hour: {hour_dist.idxmax()}:00 ({hour_dist.max():,} transactions)\")\n",
    "print(f\"  Lowest Hour: {hour_dist.idxmin()}:00 ({hour_dist.min():,} transactions)\")\n",
    "### 7. Save Metadata Report\n",
    "metadata_report = {\n",
    "    'dataset_name': 'clean_cc_transactions.csv',\n",
    "    'total_rows': clean_df.shape[0],\n",
    "    'total_columns': clean_df.shape[1],\n",
    "    'memory_usage_mb': clean_df.memory_usage(deep=True).sum() / 1024**2,\n",
    "    'numerical_features': numerical_cols.tolist(),\n",
    "    'categorical_features': categorical_cols.tolist(),\n",
    "    'target_column': 'Class',\n",
    "    'class_distribution': class_distribution.to_dict(),\n",
    "    'class_imbalance_ratio': imbalance_ratio,\n",
    "    'missing_values': clean_df.isnull().sum().to_dict(),\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "### 9. Data Quality Report\n",
    "print(\"\\n=== DATA QUALITY REPORT ===\")\n",
    "print(f\"‚úì No missing values (cleaned dataset)\")\n",
    "print(f\"‚úì All numerical features have valid ranges\")\n",
    "print(f\"‚úì Binary target variable (Class: 0 or 1)\")\n",
    "print(f\"‚ö†Ô∏è  Significant class imbalance detected ({imbalance_ratio:.1f}:1)\")\n",
    "print(f\"‚úì {len(clean_df[clean_df.duplicated()]):,} duplicate rows found\")\n",
    "# Check for potential outliers using IQR method\n",
    "outlier_summary = {}\n",
    "for col in numerical_cols:\n",
    "    if col != 'Class':  # Skip target variable\n",
    "        Q1 = clean_df[col].quantile(0.25)\n",
    "        Q3 = clean_df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        outliers = ((clean_df[col] < (Q1 - 1.5 * IQR)) | (clean_df[col] > (Q3 + 1.5 * IQR))).sum()\n",
    "        if outliers > 0:\n",
    "            outlier_summary[col] = outliers\n",
    "if outlier_summary:\n",
    "    print(f\"\\n‚ö†Ô∏è  Potential outliers detected (using IQR method):\")\n",
    "    for col, count in outlier_summary.items():\n",
    "        print(f\"    {col}: {count:,} ({count/len(clean_df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e9fcb0-de9a-444b-a89c-a409a0c2f11d",
   "metadata": {},
   "source": [
    "## Generate Visualization for Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4e2fc7-5aa5-4f3f-a008-ba3853f8d5af",
   "metadata": {},
   "source": [
    "### Feature Correlation Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315f7150-cd3c-4fa2-9961-16fadf42c098",
   "metadata": {},
   "source": [
    "This heatmap visualizes correlations between all numerical features in the dataset, with red indicating positive correlations and blue showing negative correlations. It helps identify multicollinearity between features (which might affect model performance) and shows which features have the strongest relationships with fraud (the 'Class' column), with darker colors indicating stronger correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e6fd79-5d07-4f13-8be7-99480946f2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical features for correlation analysis\n",
    "numerical_features = ['Time', 'Amount', 'Age', 'Tenure', 'MerchantRisk', \n",
    "                     'DeviceTrust', 'Txn24h', 'Avg30d', 'IPReputation', \n",
    "                     'Latitude', 'Longitude', 'DistFromHome', 'Hour', 'Class']\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = clean_df[numerical_features].corr()\n",
    "# Create figure and axis\n",
    "fig, ax = plt.subplots(figsize=(14, 12))\n",
    "# Create heatmap using matplotlib\n",
    "im = ax.imshow(corr_matrix, cmap='RdBu_r', aspect='auto', vmin=-1, vmax=1)\n",
    "# Set ticks and labels\n",
    "ax.set_xticks(np.arange(len(numerical_features)))\n",
    "ax.set_yticks(np.arange(len(numerical_features)))\n",
    "ax.set_xticklabels(numerical_features, rotation=45, ha='right')\n",
    "ax.set_yticklabels(numerical_features)\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(im, ax=ax)\n",
    "cbar.set_label('Correlation Coefficient', rotation=270, labelpad=20)\n",
    "# Add correlation values as text annotations\n",
    "for i in range(len(numerical_features)):\n",
    "    for j in range(len(numerical_features)):\n",
    "        value = corr_matrix.iloc[i, j]\n",
    "        # Use white text for dark backgrounds, black for light\n",
    "        text_color = 'white' if abs(value) > 0.5 else 'black'\n",
    "        text = ax.text(j, i, f'{value:.2f}', ha='center', va='center', \n",
    "                      color=text_color, fontsize=9)\n",
    "# Set title and layout\n",
    "ax.set_title('Feature Correlation Heatmap - Credit Card Fraud Detection', \n",
    "             fontsize=16, fontweight='bold', pad=20)\n",
    "# Add grid for better readability\n",
    "ax.set_xticks(np.arange(len(numerical_features) + 1) - 0.5, minor=True)\n",
    "ax.set_yticks(np.arange(len(numerical_features) + 1) - 0.5, minor=True)\n",
    "ax.grid(which='minor', color='gray', linestyle='-', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{domino_artifact_dir}/correlation_heatmap.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "# Print strongest correlations with fraud\n",
    "print(\"=== Strongest Correlations with Fraud (Class) ===\")\n",
    "fraud_corr = corr_matrix['Class'].drop('Class').sort_values(key=abs, ascending=False)\n",
    "print(\"\\nTop 5 positive correlations with fraud:\")\n",
    "print(fraud_corr[fraud_corr > 0].head())\n",
    "print(\"\\nTop 5 negative correlations with fraud:\")\n",
    "print(fraud_corr[fraud_corr < 0].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e3a349-2211-48c4-a524-98ed1df0510e",
   "metadata": {},
   "source": [
    "### Transaction Amount Distribution by Class (Fraud vs Non-Fraud)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc30de9-ff68-402c-b969-143977ed7b75",
   "metadata": {},
   "source": [
    "This plot compares the distribution of transaction amounts between legitimate and fraudulent transactions. It helps identify if fraudsters tend to target specific transaction amounts - for example, if fraud is more common in small transactions (to avoid detection) or large transactions (for maximum gain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881e480a-e846-43a9-b3b5-9c73704bca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "clean_df[clean_df['Class'] == 0]['Amount'].plot(kind='hist', bins=50, alpha=0.7, color='green', edgecolor='black')\n",
    "plt.title('Transaction Amount Distribution - Non-Fraud', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Amount')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim(0, 200)  # Limiting for better visualization\n",
    "plt.subplot(1, 2, 2)\n",
    "clean_df[clean_df['Class'] == 1]['Amount'].plot(kind='hist', bins=50, alpha=0.7, color='red', edgecolor='black')\n",
    "plt.title('Transaction Amount Distribution - Fraud', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Amount')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim(0, 200)  # Limiting for better visualization\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{domino_artifact_dir}/amount_distribution_by_class.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c581c3b3-8fe6-4a2d-abae-5433ae1ad3c6",
   "metadata": {},
   "source": [
    "### Fraud Rate by Hour of Day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffa0cee-dfcf-4af1-8491-20ae15b65a37",
   "metadata": {},
   "source": [
    "This bar chart shows the percentage of fraudulent transactions occurring at each hour of the day. It reveals temporal patterns in fraudulent activity, helping identify peak fraud hours when extra vigilance or real-time monitoring might be needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd139b9-b3f2-4504-808b-76839673e373",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_by_hour = clean_df.groupby('Hour')['Class'].agg(['mean', 'count'])\n",
    "fraud_by_hour['fraud_rate_pct'] = fraud_by_hour['mean'] * 100\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(fraud_by_hour.index, fraud_by_hour['fraud_rate_pct'], \n",
    "                color='darkblue', alpha=0.7, edgecolor='black')\n",
    "# Add value labels on bars\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "             f'{height:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "plt.title('Fraud Rate by Hour of Day', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('Hour of Day', fontsize=12)\n",
    "plt.ylabel('Fraud Rate (%)', fontsize=12)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.xticks(range(0, 24))\n",
    "plt.savefig(f\"{domino_artifact_dir}/fraud_rate_by_hour.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "# Print summary statistics\n",
    "print(f\"Peak fraud hour: {fraud_by_hour['fraud_rate_pct'].idxmax()}:00 with {fraud_by_hour['fraud_rate_pct'].max():.2f}% fraud rate\")\n",
    "print(f\"Lowest fraud hour: {fraud_by_hour['fraud_rate_pct'].idxmin()}:00 with {fraud_by_hour['fraud_rate_pct'].min():.2f}% fraud rate\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd7f9ac-e1c3-4b26-bfc3-5578184b035c",
   "metadata": {},
   "source": [
    "### Top 10 Features Correlation with Fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320002a3-74c2-46ec-9962-e5443ebd290b",
   "metadata": {},
   "source": [
    "This horizontal bar chart displays the features most strongly correlated (positively or negatively) with fraudulent transactions. Features with high positive correlation (green bars) increase with fraud likelihood, while negative correlations (red bars) indicate features that decrease when fraud is present, helping prioritize which variables to focus on in fraud detection models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c7da5b-5160-45a3-90dc-575dfe365110",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['Amount', 'Age', 'Tenure', 'MerchantRisk', 'DeviceTrust', \n",
    "                'Txn24h', 'Avg30d', 'IPReputation', 'Latitude', 'Longitude', \n",
    "                'DistFromHome']\n",
    "correlations = clean_df[numeric_cols + ['Class']].corr()['Class'].drop('Class')\n",
    "top_correlations = correlations.abs().sort_values(ascending=False).head(10)\n",
    "# Create horizontal bar plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['red' if corr < 0 else 'green' for corr in correlations[top_correlations.index]]\n",
    "bars = plt.barh(range(len(top_correlations)), top_correlations.values, color=colors, alpha=0.7)\n",
    "# Add value labels\n",
    "for i, (idx, val) in enumerate(top_correlations.items()):\n",
    "    actual_corr = correlations[idx]\n",
    "    plt.text(val + 0.005, i, f'{actual_corr:.3f}', va='center')\n",
    "plt.yticks(range(len(top_correlations)), top_correlations.index)\n",
    "plt.xlabel('Absolute Correlation with Fraud', fontsize=12)\n",
    "plt.title('Top 10 Features Correlated with Fraud', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{domino_artifact_dir}/top_features_correlation.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3f749c-5016-4cdd-8b20-e039616cc4f7",
   "metadata": {},
   "source": [
    "### Fraud Analysis by Merchant Category and Transaction Type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c910b2-92af-449a-a6e4-0437b1795bcb",
   "metadata": {},
   "source": [
    "This four-panel visualization breaks down fraud rates across different categorical variables:\n",
    "- Merchant Category: Shows which types of merchants (electronics, gas, etc.) experience the highest fraud rates\n",
    "- Transaction Type: Reveals whether purchases, transfers, or other transaction types are more vulnerable to fraud\n",
    "- Device Type: Indicates if certain devices (mobile, desktop) are preferred by fraudsters\n",
    "- Channel Distribution: Shows the overall volume distribution across different payment channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c6ee57-bcd1-4a46-948a-867e5f5ea5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with subplots for categorical analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "# 1. Fraud rate by Merchant Category\n",
    "ax1 = axes[0, 0]\n",
    "fraud_by_merchant = clean_df.groupby('MerchantCat')['Class'].agg(['mean', 'count'])\n",
    "fraud_by_merchant['fraud_rate_pct'] = fraud_by_merchant['mean'] * 100\n",
    "fraud_by_merchant = fraud_by_merchant.sort_values('fraud_rate_pct', ascending=False)\n",
    "bars1 = ax1.bar(range(len(fraud_by_merchant)), fraud_by_merchant['fraud_rate_pct'], \n",
    "                 color='purple', alpha=0.7, edgecolor='black')\n",
    "ax1.set_xticks(range(len(fraud_by_merchant)))\n",
    "ax1.set_xticklabels(fraud_by_merchant.index, rotation=45, ha='right')\n",
    "ax1.set_title('Fraud Rate by Merchant Category', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Fraud Rate (%)')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "# Add value labels\n",
    "for i, bar in enumerate(bars1):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "             f'{height:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "# 2. Fraud rate by Transaction Type\n",
    "ax2 = axes[0, 1]\n",
    "fraud_by_type = clean_df.groupby('TxType')['Class'].agg(['mean', 'count'])\n",
    "fraud_by_type['fraud_rate_pct'] = fraud_by_type['mean'] * 100\n",
    "bars2 = ax2.bar(range(len(fraud_by_type)), fraud_by_type['fraud_rate_pct'], \n",
    "             color='orange', alpha=0.7, edgecolor='black')\n",
    "ax2.set_xticks(range(len(fraud_by_type)))\n",
    "ax2.set_xticklabels(fraud_by_type.index, rotation=45, ha='right')\n",
    "ax2.set_title('Fraud Rate by Transaction Type', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('Fraud Rate (%)')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "# Add value labels\n",
    "for i, bar in enumerate(bars2):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "             f'{height:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "# 3. Fraud rate by Device Type\n",
    "ax3 = axes[1, 0]\n",
    "fraud_by_device = clean_df.groupby('DeviceType')['Class'].agg(['mean', 'count'])\n",
    "fraud_by_device['fraud_rate_pct'] = fraud_by_device['mean'] * 100\n",
    "bars3 = ax3.bar(range(len(fraud_by_device)), fraud_by_device['fraud_rate_pct'], \n",
    "                color='teal', alpha=0.7, edgecolor='black')\n",
    "ax3.set_xticks(range(len(fraud_by_device)))\n",
    "ax3.set_xticklabels(fraud_by_device.index, rotation=45, ha='right')\n",
    "ax3.set_title('Fraud Rate by Device Type', fontsize=14, fontweight='bold')\n",
    "ax3.set_ylabel('Fraud Rate (%)')\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "# Add value labels\n",
    "for i, bar in enumerate(bars3):\n",
    "    height = bar.get_height()\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "             f'{height:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "# 4. Transaction volume by channel\n",
    "ax4 = axes[1, 1]\n",
    "channel_counts = clean_df['Channel'].value_counts()\n",
    "colors_pie = ['skyblue', 'lightcoral', 'lightgreen', 'gold'][:len(channel_counts)]\n",
    "wedges, texts, autotexts = ax4.pie(channel_counts.values, labels=channel_counts.index, \n",
    "                                    autopct='%1.1f%%', colors=colors_pie, startangle=90)\n",
    "ax4.set_title('Transaction Volume by Channel', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{domino_artifact_dir}/categorical_fraud_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "# Print summary statistics\n",
    "print(\"\\n=== Fraud Analysis Summary ===\")\n",
    "print(f\"\\nHighest fraud merchant category: {fraud_by_merchant.index[0]} ({fraud_by_merchant['fraud_rate_pct'].iloc[0]:.2f}%)\")\n",
    "print(f\"Highest fraud transaction type: {fraud_by_type['fraud_rate_pct'].idxmax()} ({fraud_by_type['fraud_rate_pct'].max():.2f}%)\")\n",
    "print(f\"Highest fraud device type: {fraud_by_device['fraud_rate_pct'].idxmax()} ({fraud_by_device['fraud_rate_pct'].max():.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5accc82-332f-4158-95f4-1eb49e13bcd1",
   "metadata": {},
   "source": [
    "## Save Dataframe to Domino Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7152465d-b025-4eb2-a466-cd83e08489b6",
   "metadata": {},
   "source": [
    "**Domino Datasets** provide high-performance, versioned, and structured filesystem storage in Domino. You can use Datasets to build multiple curated collections of data in one project and share them with your collaborators to use in their projects. Likewise, you can mount Datasets from other projects in your own project if they are shared with you. You can modify the contents of a Dataset through the Domino application or through executions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055885d3-b5c0-4e59-b087-46081ab1fccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv(f\"{domino_dataset_dir}/{clean_filename}\")\n",
    "print(f\"Check to see that your dataset has been recently updated at {domino_dataset_dir}/{clean_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055e1cef-6015-41f4-b596-5a5fc1ae7e38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
